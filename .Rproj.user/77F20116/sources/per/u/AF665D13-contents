# Load necessary libraries
library(readr)
library(caret)
library(randomForest)
library(e1071)  # For SVM
library(ggplot2)
install.packages("Metrics")
library(Metrics)  # For RMSE

# Load the dataset
data <- read.csv("dataset/Walmart_Sales.csv")

# View the first few rows to understand the structure
head(data)

# Assuming 'Weekly_Sales' is the target variable
target_variable <- "Weekly_Sales"

# Split the data into training and test sets
set.seed(123)
trainIndex <- createDataPartition(data[[target_variable]], p = 0.8, list = FALSE)
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]

# Prepare a function to calculate RMSE and return a data frame
calculate_rmse <- function(model, test_data, target_variable) {
  predictions <- predict(model, test_data)
  rmse_value <- rmse(test_data[[target_variable]], predictions)
  return(rmse_value)
}

# Define a vector to store RMSE values
rmse_values <- data.frame(Model = character(), RMSE = numeric(), stringsAsFactors = FALSE)

# k-Nearest Neighbors
knn_model <- train(as.formula(paste(target_variable, "~ .")), data = train_data, method = "knn")
knn_rmse <- calculate_rmse(knn_model, test_data, target_variable)
rmse_values <- rbind(rmse_values, data.frame(Model = "k-Nearest Neighbors", RMSE = knn_rmse))

# Linear Regression
linear_model <- lm(as.formula(paste(target_variable, "~ .")), data = train_data)
linear_rmse <- calculate_rmse(linear_model, test_data, target_variable)
rmse_values <- rbind(rmse_values, data.frame(Model = "Linear Regression", RMSE = linear_rmse))

# Polynomial Regression (2nd degree)
poly_model <- lm(as.formula(paste(target_variable, "~ poly(. , 2)")), data = train_data)
poly_rmse <- calculate_rmse(poly_model, test_data, target_variable)
rmse_values <- rbind(rmse_values, data.frame(Model = "Polynomial Regression", RMSE = poly_rmse))

# Random Forest
rf_model <- randomForest(as.formula(paste(target_variable, "~ .")), data = train_data, ntree = 100)
rf_rmse <- calculate_rmse(rf_model, test_data, target_variable)
rmse_values <- rbind(rmse_values, data.frame(Model = "Random Forest", RMSE = rf_rmse))

# Support Vector Machine
svm_model <- svm(as.formula(paste(target_variable, "~ .")), data = train_data)
svm_rmse <- calculate_rmse(svm_model, test_data, target_variable)
rmse_values <- rbind(rmse_values, data.frame(Model = "Support Vector Machine", RMSE = svm_rmse))

# Plot RMSE Comparison
ggplot(rmse_values, aes(x = Model, y = RMSE, fill = Model)) +
  geom_bar(stat = "identity", width = 0.7) +
  theme_minimal() +
  labs(title = "RMSE Comparison of Models", x = "Model", y = "RMSE") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Scatter plot of Actual vs Predicted for each model
plot_actual_vs_predicted <- function(model, model_name) {
  predictions <- predict(model, test_data)
  plot_data <- data.frame(Actual = test_data[[target_variable]], Predicted = predictions)
  ggplot(plot_data, aes(x = Actual, y = Predicted)) +
    geom_point(color = "blue", alpha = 0.5) +
    geom_smooth(method = "lm", color = "red", se = FALSE) +
    labs(title = paste("Actual vs Predicted -", model_name), x = "Actual Values", y = "Predicted Values") +
    theme_minimal()
}

# Display the scatter plots
plot_actual_vs_predicted(knn_model, "k-Nearest Neighbors")
plot_actual_vs_predicted(linear_model, "Linear Regression")
plot_actual_vs_predicted(poly_model, "Polynomial Regression")
plot_actual_vs_predicted(rf_model, "Random Forest")
plot_actual_vs_predicted(svm_model, "Support Vector Machine")


